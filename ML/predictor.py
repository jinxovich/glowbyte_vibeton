"""–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""

from __future__ import annotations

import json
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional

from .data_preprocessor import DataPreprocessor
from .feature_engineering import FeatureEngineer
from .model import CoalFireModel
from .metrics import evaluate_model, print_metrics_report


class CoalCombustionPredictor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∞–º–æ–≤–æ–∑–≥–æ—Ä–∞–Ω–∏—è."""
    
    def __init__(self, data_dir: str | Path, artifacts_dir: str | Path):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞.
        
        Args:
            data_dir: –ü–∞–ø–∫–∞ —Å CSV —Ñ–∞–π–ª–∞–º–∏
            artifacts_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ (–º–æ–¥–µ–ª–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        self.data_dir = Path(data_dir)
        self.artifacts_dir = Path(artifacts_dir)
        self.artifacts_dir.mkdir(parents=True, exist_ok=True)
        
        self.preprocessor = DataPreprocessor(self.data_dir)
        self.feature_engineer = FeatureEngineer()
        self.model = CoalFireModel()
        
        self.model_path = self.artifacts_dir / "models" / "coal_fire_model.pkl"
        self.metrics_path = self.artifacts_dir / "training_metrics.json"
        self.history_path = self.artifacts_dir / "prediction_history.json"
        self.dataset_path = self.artifacts_dir / "datasets" / "training_dataset.parquet"
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if self.model_path.exists():
            try:
                self.model.load(self.model_path)
                print(f"‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑: {self.model_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
    
    def train(self) -> Dict[str, Any]:
        """
        –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
        """
        print("\n" + "="*60)
        print("üî• –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø –°–ê–ú–û–í–û–ó–ì–û–†–ê–ù–ò–Ø –£–ì–õ–Ø")
        print("="*60)
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df, y = self.preprocessor.prepare_training_data()
        
        # 2. Feature engineering
        df = self.feature_engineer.create_features(df)
        
        # 3. –í—ã–±—Ä–∞—Ç—å –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        feature_cols = self.feature_engineer.get_feature_columns()
        X = df[feature_cols].copy()
        
        # –ó–∞–ø–æ–ª–Ω–∏—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è NaN
        X = X.fillna(X.mean())
        
        print(f"\nüìä –§–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç:")
        print(f"  ‚úì –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
        print(f"  ‚úì –ü—Ä–∏–º–µ—Ä–æ–≤: {X.shape[0]}")
        print(f"  ‚úì Target (y) min/max: {y.min():.0f} / {y.max():.0f} –¥–Ω–µ–π")
        
        # 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        metrics = self.model.train(X, y, cv_splits=5)
        
        # 5. –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        y_pred = self.model.predict(X)
        full_metrics = evaluate_model(y.values, y_pred)
        
        # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        metrics.update(full_metrics)
        metrics['trained_at'] = datetime.now().isoformat()
        
        # 6. Feature importance
        importance_df = self.model.get_feature_importance(top_n=15)
        print(f"\nüìä –¢–û–ü-15 –í–ê–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
        for idx, row in importance_df.iterrows():
            print(f"  {row['feature']:40s}: {row['importance']:.4f}")
        
        metrics['feature_importance'] = importance_df.to_dict('records')
        
        # 7. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –∏ –º–µ—Ç—Ä–∏–∫–∏
        self.model.save(self.model_path)
        self._save_metrics(metrics)
        
        # 8. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç
        self.dataset_path.parent.mkdir(parents=True, exist_ok=True)
        df.to_parquet(self.dataset_path, index=False)
        print(f"‚úì –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {self.dataset_path}")
        
        # 9. –í—ã–≤–µ—Å—Ç–∏ –æ—Ç—á–µ—Ç
        print_metrics_report(metrics)
        
        return metrics
    
    def predict(self, input_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        –°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            input_df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏:
                - storage_id: ID —Å–∫–ª–∞–¥–∞
                - stack_id: ID —à—Ç–∞–±–µ–ª—è
                - measurement_date: –¥–∞—Ç–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è
                - max_temperature: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
                - pile_age_days: –≤–æ–∑—Ä–∞—Å—Ç —à—Ç–∞–±–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                - stack_mass_tons: –º–∞—Å—Å–∞ —à—Ç–∞–±–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                - weather_*: –ø–æ–≥–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if not self.model_path.exists():
            raise FileNotFoundError(
                "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ –º–µ—Ç–æ–¥ train()."
            )
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        df = input_df.copy()
        
        # –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫
        column_mapping = {
            'max_temperature': 'max_temp',
            'pile_age_days': 'days_since_formation',
            'stack_mass_tons': 'coal_weight'
        }
        df = df.rename(columns=column_mapping)
        
        # –ó–∞–ø–æ–ª–Ω–∏—Ç—å missing –∑–Ω–∞—á–µ–Ω–∏—è —Ä–∞–∑—É–º–Ω—ã–º–∏ –¥–µ—Ñ–æ–ª—Ç–∞–º–∏
        if 'days_since_formation' not in df.columns:
            df['days_since_formation'] = 30  # –°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç
        if 'coal_weight' not in df.columns:
            df['coal_weight'] = 5000  # –°—Ä–µ–¥–Ω–∏–π –≤–µ—Å
        
        # Feature engineering (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞)
        df = self._prepare_inference_features(df)
        
        # –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        feature_cols = self.feature_engineer.get_feature_columns()
        
        # –î–æ–±–∞–≤–∏—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for col in feature_cols:
            if col not in df.columns:
                df[col] = 0
        
        X = df[feature_cols].fillna(0)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å
        predictions_with_conf = self.model.predict_with_confidence(X)
        
        # –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        results = []
        for idx, row in input_df.iterrows():
            pred_row = predictions_with_conf.iloc[idx]
            
            predicted_days = pred_row['predicted_days']
            confidence = pred_row['confidence']
            risk_level = pred_row['risk_level']
            
            # –í—ã—á–∏—Å–ª–∏—Ç—å –¥–∞—Ç—É –≤–æ–∑–≥–æ—Ä–∞–Ω–∏—è
            measurement_date = pd.to_datetime(row['measurement_date'])
            predicted_date = measurement_date + timedelta(days=float(predicted_days))
            
            result = {
                'storage_id': str(row['storage_id']),
                'stack_id': str(row['stack_id']),
                'measurement_date': measurement_date.strftime('%Y-%m-%d %H:%M:%S'),
                'predicted_ttf_days': float(predicted_days),
                'predicted_combustion_date': predicted_date.strftime('%Y-%m-%d'),
                'confidence': float(confidence),
                'risk_level': str(risk_level),
                'max_temperature': float(row.get('max_temperature', 0))
            }
            
            results.append(result)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏—é
        self._save_prediction_history(results)
        
        return results
    
    def _prepare_inference_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–±–µ–∑ —Ç–∞—Ä–≥–µ—Ç–∞)."""
        df = df.copy()
        
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if 'max_temp' not in df.columns and 'max_temperature' in df.columns:
            df['max_temp'] = df['max_temperature']
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if 'measurement_date' in df.columns:
            df['measurement_date'] = pd.to_datetime(df['measurement_date'])
            df['month'] = df['measurement_date'].dt.month
            df['season'] = df['month'].map({
                12: 0, 1: 0, 2: 0,
                3: 1, 4: 1, 5: 1,
                6: 2, 7: 2, 8: 2,
                9: 3, 10: 3, 11: 3
            })
            df['day_of_week'] = df['measurement_date'].dt.dayofweek
        
        # –ó–∞–ø–æ–ª–Ω–∏—Ç—å –ø–æ–≥–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å—Ä–µ–¥–Ω–∏–º–∏ –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
        weather_defaults = {
            'weather_temp': 15.0,
            'weather_humidity': 60.0,
            'weather_precipitation': 0.0,
            'wind_speed_avg': 5.0,
            'wind_speed_max': 10.0,
            'weather_cloudcover': 50.0
        }
        
        for col, default_val in weather_defaults.items():
            if col not in df.columns:
                df[col] = default_val
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df['thermal_stress_index'] = (
            df['max_temp'] * 
            (1 - df['weather_humidity'] / 100) * 
            (1 + df['wind_speed_avg'] / 10)
        )
        
        df['temp_diff_internal_external'] = df['max_temp'] - df['weather_temp']
        
        df['dryness_index'] = (
            (100 - df['weather_humidity']) * 
            (1 / (df['weather_precipitation'] + 1))
        )
        
        df['oxidation_index'] = (
            df['max_temp'] + 
            df['wind_speed_avg'] * 5 - 
            df['weather_humidity'] * 0.5
        )
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ
        df['coal_type_encoded'] = 0
        df['storage_id_encoded'] = pd.factorize(df['storage_id'])[0]
        
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df['low_humidity_indicator'] = (df['weather_humidity'] < 50).astype(int)
        df['high_wind_indicator'] = (df['wind_speed_avg'] > 10).astype(int)
        df['high_temp_indicator'] = (df['max_temp'] > 40).astype(int)
        df['extreme_temp_indicator'] = (df['max_temp'] > 60).astype(int)
        
        # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è, rolling –∏ lag features = 0 (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –Ω—É–∂–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è)
        rolling_features = [
            'temp_growth_rate', 'temp_rolling_3d_max', 'temp_rolling_3d_avg', 'temp_rolling_3d_std',
            'temp_rolling_7d_max', 'temp_rolling_7d_avg', 'temp_rolling_7d_std',
            'temp_rolling_14d_max', 'temp_rolling_14d_avg', 'temp_rolling_14d_std',
            'high_temp_days_7d', 'high_temp_days_14d', 'extreme_temp_days_7d'
        ]
        
        lag_features = [
            'max_temp_lag_1d', 'max_temp_lag_2d', 'max_temp_lag_3d', 
            'max_temp_lag_7d', 'max_temp_lag_14d',
            'weather_humidity_lag_1d', 'weather_humidity_lag_3d', 'weather_humidity_lag_7d',
            'wind_speed_avg_lag_1d', 'wind_speed_avg_lag_3d',
            'thermal_stress_index_lag_1d', 'thermal_stress_index_lag_3d', 'thermal_stress_index_lag_7d'
        ]
        
        for feat in rolling_features + lag_features:
            if feat not in df.columns:
                df[feat] = 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —à—Ç–∞–±–µ–ª—é
        df['stack_max_temp_ever'] = df['max_temp']
        df['stack_avg_temp'] = df['max_temp']
        df['stack_measurement_count'] = 1
        
        return df
    
    def load_metrics(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏."""
        if not self.metrics_path.exists():
            return {}
        
        with open(self.metrics_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _save_metrics(self, metrics: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON."""
        # Convert numpy types to Python types
        def convert_types(obj):
            import numpy as np
            if isinstance(obj, (np.integer, np.floating)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, dict):
                return {k: convert_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_types(item) for item in obj]
            return obj
        
        metrics = convert_types(metrics)
        
        with open(self.metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        
        print(f"‚úì –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {self.metrics_path}")
    
    def _save_prediction_history(self, predictions: List[Dict[str, Any]]) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π."""
        history = []
        
        if self.history_path.exists():
            with open(self.history_path, 'r', encoding='utf-8') as f:
                history = json.load(f)
        
        # –î–æ–±–∞–≤–∏—Ç—å timestamp
        for pred in predictions:
            pred['predicted_at'] = datetime.now().isoformat()
        
        history.extend(predictions)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000)
        history = history[-1000:]
        
        with open(self.history_path, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)


__all__ = ["CoalCombustionPredictor"]

