"""–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""

from __future__ import annotations

import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List
from sklearn.model_selection import train_test_split

from .data_preprocessor import DataPreprocessor
from .feature_engineering import FeatureEngineer
from .model import CoalFireModel
from .metrics import evaluate_model, print_metrics_report


class CoalCombustionPredictor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∞–º–æ–≤–æ–∑–≥–æ—Ä–∞–Ω–∏—è."""
    
    def __init__(self, data_dir: str | Path, artifacts_dir: str | Path):
        self.data_dir = Path(data_dir)
        self.artifacts_dir = Path(artifacts_dir)
        self.artifacts_dir.mkdir(parents=True, exist_ok=True)
        (self.artifacts_dir / "models").mkdir(parents=True, exist_ok=True)
        
        self.preprocessor = DataPreprocessor(self.data_dir)
        self.feature_engineer = FeatureEngineer()
        self.model = CoalFireModel()
        
        self.model_path = self.artifacts_dir / "models" / "coal_fire_model.pkl"
        self.metrics_path = self.artifacts_dir / "training_metrics.json"
        
        if self.model_path.exists():
            try:
                self.model.load(self.model_path)
            except Exception:
                pass
    
    def train(self) -> Dict[str, Any]:
        """–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å."""
        print("\n" + "="*60)
        print("üî• –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò (–§–ò–ù–ê–õ–¨–ù–´–ô –ó–ê–ü–£–°–ö)")
        print("="*60)
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞
        raw_df = self.preprocessor.prepare_full_dataset()
        if raw_df.empty: raise ValueError("–î–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç!")

        # 2. –§–∏—á–∏
        full_df = self.feature_engineer.create_features(raw_df)
        
        # 3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è (60 –¥–Ω–µ–π)
        print("\nüî™ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ (0 <= –¥–Ω–µ–π –¥–æ –ø–æ–∂–∞—Ä–∞ <= 60)...")
        train_df = full_df[
            (full_df['days_until_fire'] >= 0) & 
            (full_df['days_until_fire'] <= 60)
        ].copy()
        
        if len(train_df) < 10: raise ValueError("–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö (<10).")
            
        # 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ X –∏ y
        feature_cols = self.feature_engineer.get_feature_columns()
        for col in feature_cols:
            if col not in train_df.columns: train_df[col] = 0
        
        X = train_df[feature_cols].fillna(0)
        y = train_df['days_until_fire']
        
        print(f"  ‚úì –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(X)}")
        
        # 5. –ß–ï–°–¢–ù–û–ï –†–ê–ó–î–ï–õ–ï–ù–ò–ï (Hold-out)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)
        
        print(f"  ‚úì –û–±—É—á–µ–Ω–∏–µ –Ω–∞: {len(X_train)} —Å—Ç—Ä–æ–∫")
        print(f"  ‚úì –¢–µ—Å—Ç (–ø—Ä–æ–≤–µ—Ä–∫–∞) –Ω–∞: {len(X_test)} —Å—Ç—Ä–æ–∫")
        
        # –û–±—É—á–∞–µ–º
        self.model.train(X_train, y_train, cv_splits=5)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º
        print("\n‚öñÔ∏è  –ü–†–û–í–ï–†–ö–ê –ù–ê –û–¢–õ–û–ñ–ï–ù–ù–´–• –î–ê–ù–ù–´–•:")
        y_pred_test = self.model.predict(X_test)
        test_metrics = evaluate_model(y_test.values, y_pred_test)
        
        print_metrics_report(test_metrics)
        
        # === –ù–û–í–û–ï: –°–û–•–†–ê–ù–Ø–ï–ú –°–†–ê–í–ù–ï–ù–ò–ï –í CSV ===
        comparison_df = X_test.copy()
        comparison_df['REAL_DAYS'] = y_test.values
        comparison_df['PREDICTED_DAYS'] = np.round(y_pred_test, 1)
        comparison_df['ERROR'] = comparison_df['PREDICTED_DAYS'] - comparison_df['REAL_DAYS']
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–Ω—è—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        view_cols = ['storage_id_encoded', 'max_temp', 'days_since_formation', 'REAL_DAYS', 'PREDICTED_DAYS', 'ERROR']
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ ID, –±—ã–ª–æ –±—ã –∫—Ä—É—á–µ, –Ω–æ –æ–Ω–∏ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω—ã. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
        
        save_path = self.artifacts_dir / "final_comparison.csv"
        comparison_df.to_csv(save_path, index=False)
        print(f"üíæ –§–∞–π–ª —Å–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
        print("   (–û—Ç–∫—Ä–æ–π –µ–≥–æ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–∞—Ç—ã!)")

        # === –ù–û–í–û–ï: –ü–û–ö–ê–ó–´–í–ê–ï–ú –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í ===
        print("\nüîç –¢–û–ü-10 –ü–†–ò–ß–ò–ù –í–û–ó–ì–û–†–ê–ù–ò–Ø (Feature Importance):")
        imp = self.model.get_feature_importance(top_n=10)
        print(imp.to_string(index=False))
        
        # 6. –§–∏–Ω–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        self.model.model.fit(X, y, verbose=False)
        self.model.save(self.model_path)
        self._save_metrics(test_metrics)
        
        return test_metrics
    
    def predict(self, input_df: pd.DataFrame) -> List[Dict[str, Any]]:
        if not self.model_path.exists(): raise FileNotFoundError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
        df = input_df.copy()
        rename_map = {'max_temperature': 'max_temp', 'pile_age_days': 'days_since_formation', 'stack_mass_tons': 'coal_weight'}
        df = df.rename(columns=rename_map)
        
        if 'days_since_formation' not in df.columns: df['days_since_formation'] = 0
        for col in ['weather_temp', 'weather_humidity', 'wind_speed_avg']:
            if col not in df.columns: df[col] = 0
                
        df['temp_growth_rate'] = 0 
        df['thermal_stress_index'] = df['max_temp'] * (1 - df.get('weather_humidity', 50)/200)
        
        feature_cols = self.feature_engineer.get_feature_columns()
        for col in feature_cols:
            if col not in df.columns: df[col] = 0
        X = df[feature_cols].fillna(0)
        preds = self.model.predict_with_confidence(X)
        
        results = []
        for i, row in df.iterrows():
            p_days = preds.iloc[i]['predicted_days']
            results.append({
                'storage_id': str(row.get('storage_id', '')),
                'stack_id': str(row.get('stack_id', '')),
                'predicted_ttf_days': float(p_days),
                'risk_level': str(preds.iloc[i]['risk_level']),
                'confidence': float(preds.iloc[i]['confidence'])
            })
        return results

    def _save_metrics(self, metrics: Dict[str, Any]) -> None:
        def sanitize(obj):
            if isinstance(obj, dict): return {k: sanitize(v) for k, v in obj.items()}
            elif isinstance(obj, list): return [sanitize(v) for v in obj]
            elif isinstance(obj, np.integer): return int(obj)
            elif isinstance(obj, np.floating): return float(obj)
            elif isinstance(obj, np.ndarray): return sanitize(obj.tolist())
            elif isinstance(obj, np.bool_): return bool(obj)
            elif pd.isna(obj): return None
            else: return obj
        clean_metrics = sanitize(metrics)
        with open(self.metrics_path, 'w', encoding='utf-8') as f:
            json.dump(clean_metrics, f, indent=2, ensure_ascii=False)