import sys
import pandas as pd
from pathlib import Path
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List
from .. import schemas, models, security, database

# --- –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô ---
# –¢–µ–∫—É—â–∏–π —Ñ–∞–π–ª: backend/app/routers/prediction.py
# –ù–∞–º –Ω—É–∂–Ω–æ –ø–æ–ø–∞—Å—Ç—å –≤ –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ (–≥–¥–µ –ø–∞–ø–∫–∏ ML –∏ backend –ª–µ–∂–∞—Ç —Ä—è–¥–æ–º)
# .parents[0] = routers
# .parents[1] = app
# .parents[2] = backend
# .parents[3] = –ö–û–†–ï–ù–¨ PROJEKTA
PROJECT_ROOT = Path(__file__).resolve().parents[3]

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –≤ sys.path, —á—Ç–æ–±—ã –ø–∏—Ç–æ–Ω –≤–∏–¥–µ–ª –º–æ–¥—É–ª—å ML
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# --- –ò–ú–ü–û–†–¢ –ù–û–í–û–ì–û –ü–†–ï–î–ò–ö–¢–û–†–ê ---
try:
    from ML.predictor import CoalCombustionPredictor
except ImportError as e:
    print(f"‚ùå –û–®–ò–ë–ö–ê –ò–ú–ü–û–†–¢–ê ML: {e}")
    print(f"   –û–∂–∏–¥–∞–µ–º—ã–π –ø—É—Ç—å –∫ ML: {PROJECT_ROOT / 'ML'}")
    # –ù–µ –ø–∞–¥–∞–µ–º —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã —Ö–æ—Ç—å —Å–≤–∞–≥–≥–µ—Ä –æ—Ç–∫—Ä—ã–ª—Å—è, –Ω–æ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ –±—É–¥–µ—Ç
    CoalCombustionPredictor = None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –º–æ–¥–µ–ª–∏ (–°–∏–Ω–≥–ª—Ç–æ–Ω)
predictor = None

def get_predictor():
    global predictor
    if predictor is None:
        if CoalCombustionPredictor is None:
             raise HTTPException(500, "ML –º–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏.")
             
        data_dir = PROJECT_ROOT / "data"
        artifacts_dir = PROJECT_ROOT / "ML" / "artifacts"
        
        print(f"üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏–∑ {artifacts_dir}...")
        predictor = CoalCombustionPredictor(data_dir, artifacts_dir)
        
    return predictor

router = APIRouter(prefix="/predict", tags=["ML Prediction"])

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤
def analyze_chemical_risks(data: schemas.PredictionInput) -> List[str]:
    warnings = []
    if data.co_level_ppm and data.co_level_ppm > 50:
        warnings.append("‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å CO! –ò–¥–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–µ –æ–∫–∏—Å–ª–µ–Ω–∏–µ.")
    if data.ash_content and data.ash_content > 15:
        warnings.append("‚ÑπÔ∏è –í—ã—Å–æ–∫–∞—è –∑–æ–ª—å–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –≤–ª–∏—è—Ç—å –Ω–∞ —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω.")
    if data.moisture_content and data.moisture_content < 5:
        warnings.append("‚ö†Ô∏è –£–≥–æ–ª—å —Å–ª–∏—à–∫–æ–º —Å—É—Ö–æ–π, —Ä–∏—Å–∫ –≤–æ–∑–≥–æ—Ä–∞–Ω–∏—è –ø–æ–≤—ã—à–µ–Ω.")
    return warnings

@router.post("/", response_model=schemas.PredictionResponse)
def predict_coal_fire(
    input_data: schemas.PredictionInput,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(security.get_current_active_user)
):
    ml_model = get_predictor()
    
    try:
        data_dict = input_data.model_dump()
        
        # –ú–ê–ü–ü–ò–ù–ì –í–°–ï–• –ü–û–õ–ï–ô (API -> ML DataFrame columns)
        mapped_data = {
            'storage_id': data_dict.get('storage_id'),
            'stack_id': data_dict.get('stack_id'),
            'max_temp': data_dict.get('max_temperature'),
            'coal_grade': data_dict.get('coal_grade'),
            'days_since_formation': data_dict.get('pile_age_days'),
            'coal_weight_storage': data_dict.get('stack_mass_tons'),
            
            # –ù–æ–≤—ã–µ –ø–æ–ª—è (–ª–æ–∫–∞—Ü–∏—è)
            'picket': data_dict.get('picket'),
            'shift': data_dict.get('shift'),
            
            # –ù–æ–≤—ã–µ –ø–æ–ª—è (–ø–æ–≥–æ–¥–∞ full)
            'weather_temp': data_dict.get('weather_temp'),
            'weather_humidity': data_dict.get('weather_humidity'),
            'pressure': data_dict.get('pressure'),
            'weather_precipitation': data_dict.get('precipitation'),
            'cloud_cover': data_dict.get('cloud_cover'),
            'visibility': data_dict.get('visibility'),
            'wind_speed_avg': data_dict.get('wind_speed'),
            'wind_speed_max': data_dict.get('wind_speed_max'),
            'wind_dir': data_dict.get('wind_direction'),
            'weather_code': data_dict.get('weather_code'),
            
            'measurement_date': data_dict.get('measurement_date')
        }
        
        input_df = pd.DataFrame([mapped_data])
        
        # –ü—Ä–µ–¥–∏–∫—Ç
        results = ml_model.predict(input_df)
        result = results[0]
        
        # –õ–æ–≥–∏–∫–∞ –≤–∞—Ä–Ω–∏–Ω–≥–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–µ–π)
        warnings = analyze_chemical_risks(input_data)
        if input_data.co_level_ppm and input_data.co_level_ppm > 100:
             result['predicted_ttf_days'] = min(result['predicted_ttf_days'], 3.0)
             result['risk_level'] = "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
             warnings.append("üî¥ SAFETY: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –≥–∞–∑–∞.")

        db_prediction = models.Prediction(
            user_id=current_user.id,
            storage_id=str(result['storage_id']),
            stack_id=str(result['stack_id']),
            input_data=data_dict,
            predicted_days=int(result['predicted_ttf_days']),
            confidence=int(result['confidence'] * 100),
            risk_level=result['risk_level']
        )
        db.add(db_prediction)
        db.commit()
        db.refresh(db_prediction)
        
        return {
            "id": db_prediction.id,
            "storage_id": db_prediction.storage_id,
            "stack_id": db_prediction.stack_id,
            "predicted_ttf_days": result['predicted_ttf_days'],
            "risk_level": result['risk_level'],
            "confidence": result['confidence'],
            "created_at": db_prediction.created_at,
            "warnings": warnings
        }
        
    except Exception as e:
        print(f"‚ùå ML Runtime Error: {e}")
        raise HTTPException(status_code=500, detail=f"ML Error: {str(e)}")


@router.post("/", response_model=schemas.PredictionResponse)
def predict_coal_fire(
    input_data: schemas.PredictionInput,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(security.get_current_active_user)
):
    ml_model = get_predictor()
    
    try:
        # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏
        # –ú–æ–¥–µ–ª—å v3.0 –ø—Ä–∏–Ω–∏–º–∞–µ—Ç DataFrame
        data_dict = input_data.model_dump()
        
        # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π Pydantic -> –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –∂–¥–µ—Ç –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –æ–Ω–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è)
        # –ù–æ predictor.py —Å–∞–º –¥–µ–ª–∞–µ—Ç rename, –ø–æ—ç—Ç–æ–º—É –ø–µ—Ä–µ–¥–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å, –≥–ª–∞–≤–Ω–æ–µ –∏–º–µ–Ω–∞ –∫–ª—é—á–µ–π
        input_df = pd.DataFrame([data_dict])
        
        # 2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π
        results = ml_model.predict(input_df)
        result = results[0]
        
        # 3. –ê–Ω–∞–ª–∏–∑ —Ö–∏–º. —Ä–∏—Å–∫–æ–≤
        warnings = analyze_chemical_risks(input_data)
        
        # Safety Layer: –ï—Å–ª–∏ CO –∑–∞—à–∫–∞–ª–∏–≤–∞–µ—Ç, —Å—Ç–∞–≤–∏–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–∏—Å–∫ –≤—Ä—É—á–Ω—É—é
        if input_data.co_level_ppm and input_data.co_level_ppm > 100:
             result['predicted_ttf_days'] = min(result['predicted_ttf_days'], 3.0)
             result['risk_level'] = "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
             warnings.append("üî¥ SAFETY: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –≥–∞–∑–∞ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç ML-–ø—Ä–æ–≥–Ω–æ–∑.")

        # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
        db_prediction = models.Prediction(
            user_id=current_user.id,
            storage_id=str(result['storage_id']),
            stack_id=str(result['stack_id']),
            input_data=data_dict,
            predicted_days=int(result['predicted_ttf_days']),
            confidence=int(result['confidence'] * 100),
            risk_level=result['risk_level']
        )
        db.add(db_prediction)
        db.commit()
        db.refresh(db_prediction)
        
        return {
            "id": db_prediction.id,
            "storage_id": db_prediction.storage_id,
            "stack_id": db_prediction.stack_id,
            "predicted_ttf_days": result['predicted_ttf_days'],
            "risk_level": result['risk_level'],
            "confidence": result['confidence'],
            "created_at": db_prediction.created_at,
            "warnings": warnings
        }
        
    except Exception as e:
        print(f"‚ùå ML Runtime Error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ ML –º–æ–¥–µ–ª–∏: {str(e)}")

@router.post("/forecast", response_model=schemas.ForecastResponse)
def simulate_future_risk(
    input_data: schemas.PredictionInput,
    current_user: models.User = Depends(security.get_current_active_user)
):
    """
    –°–∏–º—É–ª—è—Ü–∏—è –±—É–¥—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.
    """
    ml_model = get_predictor()
    
    forecast_points = []
    offsets = [0, 7, 14, 30]
    current_temp = input_data.max_temperature
    
    # –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –Ω–∞–≥—Ä–µ–≤–∞ –¥–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏
    heating_rate = 0.1 if current_temp < 30 else (0.5 if current_temp < 50 else 2.0)
    
    base_data = input_data.model_dump()
    
    for days in offsets:
        # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è
        scenario_data = base_data.copy()
        scenario_data['pile_age_days'] = (scenario_data.get('pile_age_days') or 0) + days
        scenario_data['max_temperature'] = current_temp + (heating_rate * days)
        
        # –°–æ–∑–¥–∞–µ–º DF –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
        scenario_df = pd.DataFrame([scenario_data])
        
        # –ü—Ä–µ–¥–∏–∫—Ç
        res_list = ml_model.predict(scenario_df)
        res = res_list[0]
        
        forecast_points.append({
            "days_offset": days,
            "predicted_days_left": res['predicted_ttf_days'],
            "risk_level": res['risk_level'],
            "estimated_temp": round(scenario_data['max_temperature'], 1)
        })
        
    return {
        "storage_id": input_data.storage_id,
        "stack_id": input_data.stack_id,
        "current_risk": forecast_points[0]['risk_level'],
        "forecast": forecast_points
    }

@router.post("/batch", response_model=List[schemas.PredictionResponse])
def predict_batch(
    inputs: List[schemas.PredictionInput],
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(security.get_current_active_user)
):
    """–ú–∞—Å—Å–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)."""
    results = []
    for item in inputs:
        res = predict_coal_fire(item, db, current_user)
        results.append(res)
    return results

@router.get("/history", response_model=list[schemas.PredictionResponse])
def get_history(
    limit: int = 100,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(security.get_current_active_user)
):
    return db.query(models.Prediction).filter(
        models.Prediction.user_id == current_user.id
    ).order_by(models.Prediction.created_at.desc()).limit(limit).all()

@router.get("/dashboard")
def get_dashboard_data(
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(security.get_current_active_user)
):
    predictions = db.query(models.Prediction).filter(
        models.Prediction.user_id == current_user.id
    ).order_by(models.Prediction.created_at.desc()).all()
    
    total = len(predictions)
    risk_counts = {}
    for p in predictions:
        risk = p.risk_level
        risk_counts[risk] = risk_counts.get(risk, 0) + 1
    
    critical_count = sum(1 for p in predictions if p.predicted_days < 7)
    avg_confidence = sum(p.confidence for p in predictions) / total if total > 0 else 0
    
    recent_predictions = []
    for p in predictions[:10]:
        recent_predictions.append({
            "id": p.id,
            "storage_id": p.storage_id,
            "stack_id": p.stack_id,
            "predicted_days": p.predicted_days,
            "risk_level": p.risk_level,
            "confidence": p.confidence,
            "created_at": p.created_at.isoformat()
        })
    
    return {
        "total_predictions": total,
        "critical_count": critical_count,
        "avg_confidence": int(avg_confidence),
        "risk_distribution": risk_counts,
        "recent_predictions": recent_predictions,
        "all_predictions": [
            {
                "id": p.id,
                "storage_id": p.storage_id,
                "stack_id": p.stack_id,
                "predicted_days": p.predicted_days,
                "risk_level": p.risk_level,
                "confidence": p.confidence,
                "created_at": p.created_at.isoformat(),
                "input_data": p.input_data
            }
            for p in predictions
        ]
    }