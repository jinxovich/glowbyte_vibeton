import sys
import pandas as pd
from pathlib import Path
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from .. import schemas, models, security, database

# --- –ú–ê–ì–ò–Ø –ò–ú–ü–û–†–¢–ê ML ---
# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø–∞–ø–∫—É ML
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

try:
    from ML.simple_predictor import SimpleCoalFirePredictor
except ImportError:
    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å ML –º–æ–¥—É–ª—å. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ –∏–∑ –∫–æ—Ä–Ω—è.")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –º–æ–¥–µ–ª–∏ (–°–∏–Ω–≥–ª—Ç–æ–Ω)
predictor = None

def get_predictor():
    global predictor
    if predictor is None:
        data_dir = PROJECT_ROOT / "data"
        artifacts_dir = PROJECT_ROOT / "ML" / "artifacts"
        predictor = SimpleCoalFirePredictor(data_dir, artifacts_dir)
        try:
            predictor.load_model()
        except FileNotFoundError:
            print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞! –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python ML/train_simple.py")
    return predictor

router = APIRouter(prefix="/predict", tags=["ML Prediction"])

@router.post("/", response_model=schemas.PredictionResponse)
def predict_coal_fire(
    input_data: schemas.PredictionInput,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(security.get_current_active_user)
):
    ml_model = get_predictor()
    
    try:
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª—å—é
        data = input_data.model_dump()
        result = ml_model.predict(
            storage_id=data.get('storage_id', '11'),
            stack_id=data.get('stack_id', '11'),
            max_temp=data.get('max_temperature', 40),
            storage_days=data.get('pile_age_days', 30),
            mass_tons=data.get('stack_mass_tons', 5000),
            humidity=data.get('weather_humidity', 50),
            air_temp=data.get('weather_temp', 15),
            wind_speed=data.get('wind_speed', 3),
            precipitation=data.get('precipitation', 0)
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î (–ò—Å—Ç–æ—Ä–∏—è)
        db_prediction = models.Prediction(
            user_id=current_user.id,
            storage_id=result['storage_id'],
            stack_id=result['stack_id'],
            input_data=input_data.model_dump(),
            predicted_days=int(result['days_to_fire']),
            confidence=int(result['confidence'] * 100),
            risk_level=result['risk_level']
        )
        db.add(db_prediction)
        db.commit()
        db.refresh(db_prediction)
        
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ID={db_prediction.id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {current_user.id}: {result['days_to_fire']} –¥–Ω–µ–π, —Ä–∏—Å–∫={result['risk_level']}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        return {
            "id": db_prediction.id,
            "storage_id": db_prediction.storage_id,
            "stack_id": db_prediction.stack_id,
            "predicted_ttf_days": result['days_to_fire'],
            "risk_level": result['risk_level'],
            "confidence": result['confidence'],
            "created_at": db_prediction.created_at
        }
        
    except Exception as e:
        print(f"ML Error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ ML –º–æ–¥–µ–ª–∏: {str(e)}")

@router.get("/history", response_model=list[schemas.PredictionResponse])
def get_history(
    limit: int = 100,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(security.get_current_active_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    return db.query(models.Prediction).filter(
        models.Prediction.user_id == current_user.id
    ).order_by(models.Prediction.created_at.desc()).limit(limit).all()

@router.get("/dashboard")
def get_dashboard_data(
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(security.get_current_active_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞: –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, —Ä–∏—Å–∫–∏."""
    
    # –í—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–ë–ï–ó –õ–ò–ú–ò–¢–ê!)
    predictions = db.query(models.Prediction).filter(
        models.Prediction.user_id == current_user.id
    ).order_by(models.Prediction.created_at.desc()).all()
    
    print(f"üîç Dashboard: –ù–∞–π–¥–µ–Ω–æ {len(predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {current_user.id}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total = len(predictions)
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∏—Å–∫–∞–º
    risk_counts = {}
    for p in predictions:
        risk = p.risk_level
        risk_counts[risk] = risk_counts.get(risk, 0) + 1
    
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ (< 7 –¥–Ω–µ–π)
    critical_count = sum(1 for p in predictions if p.predicted_days < 7)
    
    # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    avg_confidence = sum(p.confidence for p in predictions) / total if total > 0 else 0
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –í—Å–µ–≥–æ={total}, –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö={critical_count}, –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={avg_confidence}")
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
    recent_predictions = []
    for p in predictions[:10]:
        recent_predictions.append({
            "id": p.id,
            "storage_id": p.storage_id,
            "stack_id": p.stack_id,
            "predicted_days": p.predicted_days,
            "risk_level": p.risk_level,
            "confidence": p.confidence,
            "created_at": p.created_at.isoformat()
        })
    
    result = {
        "total_predictions": total,
        "critical_count": critical_count,
        "avg_confidence": int(avg_confidence),
        "risk_distribution": risk_counts,
        "recent_predictions": recent_predictions,
        "all_predictions": [
            {
                "id": p.id,
                "storage_id": p.storage_id,
                "stack_id": p.stack_id,
                "predicted_days": p.predicted_days,
                "risk_level": p.risk_level,
                "confidence": p.confidence,
                "created_at": p.created_at.isoformat(),
                "input_data": p.input_data
            }
            for p in predictions
        ]
    }
    
    return result